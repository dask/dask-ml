 
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>dask_ml.feature_extraction.text.HashingVectorizer &#8212; dask-ml 2024.4.2 documentation</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/style.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx-book-theme.9d8b4a8b9bb19db25eeaddc40d639ba2.js"></script>
    <link rel="shortcut icon" href="_static/images/favicon.svg"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="dask_ml.feature_extraction.text.FeatureHasher" href="dask_ml.feature_extraction.text.FeatureHasher.html" />
    <link rel="prev" title="dask_ml.feature_extraction.text.CountVectorizer" href="dask_ml.feature_extraction.text.CountVectorizer.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
<!-- Google Tag Manager (noscript) -->
<noscript
  ><iframe
    src="https://www.googletagmanager.com/ns.html?id=GTM-P4GQM59"
    height="0"
    width="0"
    style="display: none; visibility: hidden"
  ></iframe
></noscript>
<!-- End Google Tag Manager (noscript) -->
<nav class="dask-nav container-fluid">
  <ul>
    <li class="logo">
      <a href="https://docs.dask.org/">
        <img
          class="caption"
          src="../../_static/images/dask-horizontal-white.svg"
        />
      </a>
    </li>

    <li>
      <a href="https://docs.dask.org/">Dask</a>
    </li>

    <li>
      <a href="https://distributed.dask.org/">Distributed</a>
    </li>

    <li>
      <a href="https://ml.dask.org/">Dask ML</a>
    </li>

    <li>
      <a href="https://examples.dask.org/">Examples</a>
    </li>

    <li>
      <a href="https://docs.dask.org/en/latest/ecosystem.html">Ecosystem</a>
    </li>

    <li>
      <a href="https://docs.dask.org/en/latest/support.html">Community</a>
    </li>
  </ul>
</nav>


    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<div class="col-12 col-md-3 bd-sidebar site-navigation " id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Get Started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../install.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../examples.html">
   Examples
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Use
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../preprocessing.html">
   Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cross_validation.html">
   Cross Validation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../hyper-parameter-search.html">
   Hyper Parameter Search
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../compose.html">
   Pipelines and Composite Estimators
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../glm.html">
   Generalized Linear Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../naive-bayes.html">
   Naive Bayes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../meta-estimators.html">
   Parallel Meta-estimators
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../incremental.html">
   Incremental Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../clustering.html">
   Clustering
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../api.html">
   API Reference
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.model_selection.train_test_split.html">
     dask_ml.model_selection.train_test_split
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.model_selection.ShuffleSplit.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.model_selection
      </span>
     </code>
     .ShuffleSplit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.model_selection.KFold.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.model_selection
      </span>
     </code>
     .KFold
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.model_selection.GridSearchCV.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.model_selection
      </span>
     </code>
     .GridSearchCV
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.model_selection.RandomizedSearchCV.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.model_selection
      </span>
     </code>
     .RandomizedSearchCV
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.model_selection.IncrementalSearchCV.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.model_selection
      </span>
     </code>
     .IncrementalSearchCV
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.model_selection.HyperbandSearchCV.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.model_selection
      </span>
     </code>
     .HyperbandSearchCV
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.model_selection.SuccessiveHalvingSearchCV.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.model_selection
      </span>
     </code>
     .SuccessiveHalvingSearchCV
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.model_selection.InverseDecaySearchCV.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.model_selection
      </span>
     </code>
     .InverseDecaySearchCV
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.ensemble.BlockwiseVotingClassifier.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.ensemble
      </span>
     </code>
     .BlockwiseVotingClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.ensemble.BlockwiseVotingRegressor.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.ensemble
      </span>
     </code>
     .BlockwiseVotingRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.linear_model.LinearRegression.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.linear_model
      </span>
     </code>
     .LinearRegression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.linear_model.LogisticRegression.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.linear_model
      </span>
     </code>
     .LogisticRegression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.linear_model.PoissonRegression.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.linear_model
      </span>
     </code>
     .PoissonRegression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.naive_bayes.GaussianNB.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.naive_bayes
      </span>
     </code>
     .GaussianNB
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.wrappers.ParallelPostFit.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.wrappers
      </span>
     </code>
     .ParallelPostFit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.wrappers.Incremental.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.wrappers
      </span>
     </code>
     .Incremental
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.cluster.KMeans.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.cluster
      </span>
     </code>
     .KMeans
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.cluster.SpectralClustering.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.cluster
      </span>
     </code>
     .SpectralClustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.decomposition.IncrementalPCA.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.decomposition
      </span>
     </code>
     .IncrementalPCA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.decomposition.PCA.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.decomposition
      </span>
     </code>
     .PCA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.decomposition.TruncatedSVD.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.decomposition
      </span>
     </code>
     .TruncatedSVD
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.preprocessing.StandardScaler.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.preprocessing
      </span>
     </code>
     .StandardScaler
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.preprocessing.RobustScaler.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.preprocessing
      </span>
     </code>
     .RobustScaler
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.preprocessing.MinMaxScaler.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.preprocessing
      </span>
     </code>
     .MinMaxScaler
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.preprocessing.QuantileTransformer.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.preprocessing
      </span>
     </code>
     .QuantileTransformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.preprocessing.Categorizer.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.preprocessing
      </span>
     </code>
     .Categorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.preprocessing.DummyEncoder.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.preprocessing
      </span>
     </code>
     .DummyEncoder
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.preprocessing.OrdinalEncoder.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.preprocessing
      </span>
     </code>
     .OrdinalEncoder
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.preprocessing.LabelEncoder.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.preprocessing
      </span>
     </code>
     .LabelEncoder
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.preprocessing.PolynomialFeatures.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.preprocessing
      </span>
     </code>
     .PolynomialFeatures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.preprocessing.BlockTransformer.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.preprocessing
      </span>
     </code>
     .BlockTransformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.feature_extraction.text.CountVectorizer.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.feature_extraction.text
      </span>
     </code>
     .CountVectorizer
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.feature_extraction.text
      </span>
     </code>
     .HashingVectorizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.feature_extraction.text.FeatureHasher.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.feature_extraction.text
      </span>
     </code>
     .FeatureHasher
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.compose.ColumnTransformer.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.compose
      </span>
     </code>
     .ColumnTransformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.compose.make_column_transformer.html">
     dask_ml.compose.make_column_transformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.impute.SimpleImputer.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.impute
      </span>
     </code>
     .SimpleImputer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.metrics.mean_absolute_error.html">
     dask_ml.metrics.mean_absolute_error
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.metrics.mean_absolute_percentage_error.html">
     dask_ml.metrics.mean_absolute_percentage_error
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.metrics.mean_squared_error.html">
     dask_ml.metrics.mean_squared_error
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.metrics.mean_squared_log_error.html">
     dask_ml.metrics.mean_squared_log_error
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.metrics.r2_score.html">
     dask_ml.metrics.r2_score
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.metrics.accuracy_score.html">
     dask_ml.metrics.accuracy_score
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.metrics.log_loss.html">
     dask_ml.metrics.log_loss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.xgboost.XGBClassifier.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.xgboost
      </span>
     </code>
     .XGBClassifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.xgboost.XGBRegressor.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       dask_ml.xgboost
      </span>
     </code>
     .XGBRegressor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.xgboost.train.html">
     dask_ml.xgboost.train
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.xgboost.predict.html">
     dask_ml.xgboost.predict
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.datasets.make_counts.html">
     dask_ml.datasets.make_counts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.datasets.make_blobs.html">
     dask_ml.datasets.make_blobs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.datasets.make_regression.html">
     dask_ml.datasets.make_regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.datasets.make_classification.html">
     dask_ml.datasets.make_classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dask_ml.datasets.make_classification_df.html">
     dask_ml.datasets.make_classification_df
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Integration
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../joblib.html">
   Scikit-Learn &amp; Joblib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../xgboost.html">
   XGBoost &amp; LightGBM
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pytorch.html">
   PyTorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../keras.html">
   Keras and Tensorflow
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Develop
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../changelog.html">
   Changelog
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../contributing.html">
   Contributing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../roadmap.html">
   Dask-ML Roadmap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../history.html">
   History
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<!-- This is an invisible pixel that we watch to see if we've scrolled. -->
<div class="sbt-scroll-pixel-helper"></div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            <div class="topbar-left">
                
                <label class="nav-toggle-button" for="__navigation">
                    <div class="visually-hidden">Toggle navigation</div>
                    <i class="fas fa-bars"></i>
                </label>
                
            </div>
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/modules/generated/dask_ml.feature_extraction.text.HashingVectorizer.rst.txt"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.rst</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>dask_ml.feature_extraction.text.HashingVectorizer</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="section" id="dask-ml-feature-extraction-text-hashingvectorizer">
<h1><code class="xref py py-mod docutils literal notranslate"><span class="pre">dask_ml.feature_extraction.text</span></code>.HashingVectorizer<a class="headerlink" href="#dask-ml-feature-extraction-text-hashingvectorizer" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="dask_ml.feature_extraction.text.HashingVectorizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dask_ml.feature_extraction.text.</span></span><span class="sig-name descname"><span class="pre">HashingVectorizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input='content'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding='utf-8'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decode_error='strict'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strip_accents=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lowercase=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessor=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokenizer=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_words=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_pattern='(?u)\\b\\w\\w+\\b'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ngram_range=(1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">1)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">analyzer='word'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_features=1048576</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">binary=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm='l2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alternate_sign=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.float64'&gt;</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dask_ml.feature_extraction.text.HashingVectorizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert a collection of text documents to a matrix of token occurrences.</p>
<p>It turns a collection of text documents into a scipy.sparse matrix holding
token occurrence counts (or binary occurrence information), possibly
normalized as token frequencies if norm=’l1’ or projected on the euclidean
unit sphere if norm=’l2’.</p>
<p>This text vectorizer implementation uses the hashing trick to find the
token string name to feature integer index mapping.</p>
<p>This strategy has several advantages:</p>
<ul class="simple">
<li><p>it is very low memory scalable to large datasets as there is no need to
store a vocabulary dictionary in memory.</p></li>
<li><p>it is fast to pickle and un-pickle as it holds no state besides the
constructor parameters.</p></li>
<li><p>it can be used in a streaming (partial fit) or parallel pipeline as there
is no state computed during fit.</p></li>
</ul>
<p>There are also a couple of cons (vs using a CountVectorizer with an
in-memory vocabulary):</p>
<ul class="simple">
<li><p>there is no way to compute the inverse transform (from feature indices to
string feature names) which can be a problem when trying to introspect
which features are most important to a model.</p></li>
<li><p>there can be collisions: distinct tokens can be mapped to the same
feature index. However in practice this is rarely an issue if n_features
is large enough (e.g. 2 ** 18 for text classification problems).</p></li>
<li><p>no IDF weighting as this would render the transformer stateful.</p></li>
</ul>
<p>The hash function employed is the signed 32-bit version of Murmurhash3.</p>
<p>For an efficiency comparison of the different feature extractors, see
<a class="reference external" href="https://scikit-learn.org/stable/auto_examples/text/plot_hashing_vs_dict_vectorizer.html#sphx-glr-auto-examples-text-plot-hashing-vs-dict-vectorizer-py" title="(in scikit-learn v1.4)"><span>FeatureHasher and DictVectorizer Comparison</span></a>.</p>
<p>Read more in the <a class="reference external" href="https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction" title="(in scikit-learn v1.4)"><span class="xref std std-ref">User Guide</span></a>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>input</strong><span class="classifier">{‘filename’, ‘file’, ‘content’}, default=’content’</span></dt><dd><ul class="simple">
<li><p>If <cite>‘filename’</cite>, the sequence passed as an argument to fit is
expected to be a list of filenames that need reading to fetch
the raw content to analyze.</p></li>
<li><p>If <cite>‘file’</cite>, the sequence items must have a ‘read’ method (file-like
object) that is called to fetch the bytes in memory.</p></li>
<li><p>If <cite>‘content’</cite>, the input is expected to be a sequence of items that
can be of type string or byte.</p></li>
</ul>
</dd>
<dt><strong>encoding</strong><span class="classifier">str, default=’utf-8’</span></dt><dd><p>If bytes or files are given to analyze, this encoding is used to
decode.</p>
</dd>
<dt><strong>decode_error</strong><span class="classifier">{‘strict’, ‘ignore’, ‘replace’}, default=’strict’</span></dt><dd><p>Instruction on what to do if a byte sequence is given to analyze that
contains characters not of the given <cite>encoding</cite>. By default, it is
‘strict’, meaning that a UnicodeDecodeError will be raised. Other
values are ‘ignore’ and ‘replace’.</p>
</dd>
<dt><strong>strip_accents</strong><span class="classifier">{‘ascii’, ‘unicode’} or callable, default=None</span></dt><dd><p>Remove accents and perform other character normalization
during the preprocessing step.
‘ascii’ is a fast method that only works on characters that have
a direct ASCII mapping.
‘unicode’ is a slightly slower method that works on any character.
None (default) means no character normalization is performed.</p>
<p>Both ‘ascii’ and ‘unicode’ use NFKD normalization from
<a class="reference external" href="https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize" title="(in Python v3.12)"><code class="xref py py-func docutils literal notranslate"><span class="pre">unicodedata.normalize()</span></code></a>.</p>
</dd>
<dt><strong>lowercase</strong><span class="classifier">bool, default=True</span></dt><dd><p>Convert all characters to lowercase before tokenizing.</p>
</dd>
<dt><strong>preprocessor</strong><span class="classifier">callable, default=None</span></dt><dd><p>Override the preprocessing (string transformation) stage while
preserving the tokenizing and n-grams generation steps.
Only applies if <code class="docutils literal notranslate"><span class="pre">analyzer</span></code> is not callable.</p>
</dd>
<dt><strong>tokenizer</strong><span class="classifier">callable, default=None</span></dt><dd><p>Override the string tokenization step while preserving the
preprocessing and n-grams generation steps.
Only applies if <code class="docutils literal notranslate"><span class="pre">analyzer</span> <span class="pre">==</span> <span class="pre">'word'</span></code>.</p>
</dd>
<dt><strong>stop_words</strong><span class="classifier">{‘english’}, list, default=None</span></dt><dd><p>If ‘english’, a built-in stop word list for English is used.
There are several known issues with ‘english’ and you should
consider an alternative (see <a class="reference external" href="https://scikit-learn.org/stable/modules/feature_extraction.html#stop-words" title="(in scikit-learn v1.4)"><span>Using stop words</span></a>).</p>
<p>If a list, that list is assumed to contain stop words, all of which
will be removed from the resulting tokens.
Only applies if <code class="docutils literal notranslate"><span class="pre">analyzer</span> <span class="pre">==</span> <span class="pre">'word'</span></code>.</p>
</dd>
<dt><strong>token_pattern</strong><span class="classifier">str or None, default=r”(?u)\b\w\w+\b”</span></dt><dd><p>Regular expression denoting what constitutes a “token”, only used
if <code class="docutils literal notranslate"><span class="pre">analyzer</span> <span class="pre">==</span> <span class="pre">'word'</span></code>. The default regexp selects tokens of 2
or more alphanumeric characters (punctuation is completely ignored
and always treated as a token separator).</p>
<p>If there is a capturing group in token_pattern then the
captured group content, not the entire match, becomes the token.
At most one capturing group is permitted.</p>
</dd>
<dt><strong>ngram_range</strong><span class="classifier">tuple (min_n, max_n), default=(1, 1)</span></dt><dd><p>The lower and upper boundary of the range of n-values for different
n-grams to be extracted. All values of n such that min_n &lt;= n &lt;= max_n
will be used. For example an <code class="docutils literal notranslate"><span class="pre">ngram_range</span></code> of <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">1)</span></code> means only
unigrams, <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">2)</span></code> means unigrams and bigrams, and <code class="docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">2)</span></code> means
only bigrams.
Only applies if <code class="docutils literal notranslate"><span class="pre">analyzer</span></code> is not callable.</p>
</dd>
<dt><strong>analyzer</strong><span class="classifier">{‘word’, ‘char’, ‘char_wb’} or callable, default=’word’</span></dt><dd><p>Whether the feature should be made of word or character n-grams.
Option ‘char_wb’ creates character n-grams only from text inside
word boundaries; n-grams at the edges of words are padded with space.</p>
<p>If a callable is passed it is used to extract the sequence of features
out of the raw, unprocessed input.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.21: </span>Since v0.21, if <code class="docutils literal notranslate"><span class="pre">input</span></code> is <code class="docutils literal notranslate"><span class="pre">'filename'</span></code> or <code class="docutils literal notranslate"><span class="pre">'file'</span></code>, the data
is first read from the file and then passed to the given callable
analyzer.</p>
</div>
</dd>
<dt><strong>n_features</strong><span class="classifier">int, default=(2 ** 20)</span></dt><dd><p>The number of features (columns) in the output matrices. Small numbers
of features are likely to cause hash collisions, but large numbers
will cause larger coefficient dimensions in linear learners.</p>
</dd>
<dt><strong>binary</strong><span class="classifier">bool, default=False</span></dt><dd><p>If True, all non zero counts are set to 1. This is useful for discrete
probabilistic models that model binary events rather than integer
counts.</p>
</dd>
<dt><strong>norm</strong><span class="classifier">{‘l1’, ‘l2’}, default=’l2’</span></dt><dd><p>Norm used to normalize term vectors. None for no normalization.</p>
</dd>
<dt><strong>alternate_sign</strong><span class="classifier">bool, default=True</span></dt><dd><p>When True, an alternating sign is added to the features as to
approximately conserve the inner product in the hashed space even for
small n_features. This approach is similar to sparse random projection.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.19.</span></p>
</div>
</dd>
<dt><strong>dtype</strong><span class="classifier">type, default=np.float64</span></dt><dd><p>Type of the matrix returned by fit_transform() or transform().</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="dask_ml.feature_extraction.text.CountVectorizer.html#dask_ml.feature_extraction.text.CountVectorizer" title="dask_ml.feature_extraction.text.CountVectorizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CountVectorizer</span></code></a></dt><dd><p>Convert a collection of text documents to a matrix of token counts.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">TfidfVectorizer</span></code></dt><dd><p>Convert a collection of raw documents to a matrix of TF-IDF features.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>This estimator is <a class="reference external" href="https://scikit-learn.org/stable/glossary.html#term-stateless" title="(in scikit-learn v1.4)"><span class="xref std std-term">stateless</span></a> and does not need to be fitted.
However, we recommend to call <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit_transform()</span></code> instead of
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transform()</span></code>, as parameter validation is only performed in
<code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code>.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">HashingVectorizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>    <span class="s1">&#39;This is the first document.&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s1">&#39;This document is the second document.&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s1">&#39;And this is the third one.&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s1">&#39;Is this the first document?&#39;</span><span class="p">,</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">HashingVectorizer</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(4, 16)</span>
</pre></div>
</div>
<p class="rubric">Methods</p>
<table class="autosummary longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">build_analyzer</span></code>()</p></td>
<td><p>Return a callable to process input data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">build_preprocessor</span></code>()</p></td>
<td><p>Return a function to preprocess the text before tokenization.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">build_tokenizer</span></code>()</p></td>
<td><p>Return a function that splits a string into a sequence of tokens.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">decode</span></code>(doc)</p></td>
<td><p>Decode the input into a string of unicode symbols.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code>(X[, y])</p></td>
<td><p>Only validates estimator's parameters.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code>(X[, y])</p></td>
<td><p>Transform a sequence of documents to a document-term matrix.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_metadata_routing</span></code>()</p></td>
<td><p>Get metadata routing of this object.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_stop_words</span></code>()</p></td>
<td><p>Build or fetch the effective stop words list.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_fit</span></code>(X[, y])</p></td>
<td><p>Only validates estimator's parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_output</span></code>(*[, transform])</p></td>
<td><p>Set output container.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_transform_request</span></code>(*[, raw_X])</p></td>
<td><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">transform</span></code> method.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code>(raw_X)</p></td>
<td><p>Transform a sequence of documents to a document-term matrix.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="dask_ml.feature_extraction.text.HashingVectorizer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input='content'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding='utf-8'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decode_error='strict'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strip_accents=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lowercase=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessor=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokenizer=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_words=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_pattern='(?u)\\b\\w\\w+\\b'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ngram_range=(1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">1)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">analyzer='word'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_features=1048576</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">binary=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm='l2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alternate_sign=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.float64'&gt;</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dask_ml.feature_extraction.text.HashingVectorizer.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<div class="clearer"></div></div>


              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="dask_ml.feature_extraction.text.CountVectorizer.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dask_ml.feature_extraction.text</span></code>.CountVectorizer</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="dask_ml.feature_extraction.text.FeatureHasher.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dask_ml.feature_extraction.text</span></code>.FeatureHasher</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Dask developers<br/>
    
        &copy; Copyright 2017, Dask developers.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

<!-- Google Tag Manager -->
<script>
  (function (w, d, s, l, i) {
    w[l] = w[l] || [];
    w[l].push({
      "gtm.start": new Date().getTime(),
      event: "gtm.js",
    });
    var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s),
      dl = l != "dataLayer" ? "&l=" + l : "";
    j.async = true;
    j.src = "https://www.googletagmanager.com/gtm.js?id=" + i + dl;
    f.parentNode.insertBefore(j, f);
  })(
    window,
    document,
    "script",
    "dataLayer",
    "GTM-P4GQM59"
  );
</script>
<!-- End Google Tag Manager -->

  </body>
</html>